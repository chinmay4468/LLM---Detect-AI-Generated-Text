{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":61542,"databundleVersionId":6888007,"sourceType":"competition"},{"sourceId":6971638,"sourceType":"datasetVersion","datasetId":3961875},{"sourceId":7087976,"sourceType":"datasetVersion","datasetId":4084007}],"dockerImageVersionId":30589,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-30T07:14:06.079488Z","iopub.execute_input":"2023-11-30T07:14:06.080677Z","iopub.status.idle":"2023-11-30T07:14:06.091286Z","shell.execute_reply.started":"2023-11-30T07:14:06.080632Z","shell.execute_reply":"2023-11-30T07:14:06.090375Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"/kaggle/input/llm-detect-ai-generated-text/sample_submission.csv\n/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv\n/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\n/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\n/kaggle/input/training-dataset/Generated_text.csv\n/kaggle/input/llm-7-prompt-training-dataset/train_essays_RDizzl3_seven_v2.csv\n/kaggle/input/llm-7-prompt-training-dataset/train_essays_7_prompts_v2.csv\n/kaggle/input/llm-7-prompt-training-dataset/train_essays_7_prompts.csv\n/kaggle/input/llm-7-prompt-training-dataset/train_essays_RDizzl3_seven_v1.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom collections import defaultdict, Counter\nimport re\nfrom math import log\nfrom math import exp\nfrom math import log, exp\nimport csv\nfrom collections import defaultdict\nfrom math import log, exp\nimport re\nimport re\nfrom collections import defaultdict\nfrom math import log, exp\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-11-30T07:14:06.092863Z","iopub.execute_input":"2023-11-30T07:14:06.093526Z","iopub.status.idle":"2023-11-30T07:14:06.101270Z","shell.execute_reply.started":"2023-11-30T07:14:06.093496Z","shell.execute_reply":"2023-11-30T07:14:06.100453Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"training_data  = pd.read_csv('/kaggle/input/training-dataset/Generated_text.csv')\ntraining_dataset  = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_essays.csv').to_dict('records')\ntest_data  = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\ntrain_prompts_data   = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T07:14:06.102234Z","iopub.execute_input":"2023-11-30T07:14:06.102500Z","iopub.status.idle":"2023-11-30T07:14:07.382351Z","shell.execute_reply.started":"2023-11-30T07:14:06.102471Z","shell.execute_reply":"2023-11-30T07:14:07.381277Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"train1 = training_data[training_data.RDizzl3_seven == False].reset_index(drop=True)\ntrain1=training_data[training_data[\"label\"]==1].sample(8000)\ntrain = training_data[training_data.RDizzl3_seven == True].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T07:14:07.384457Z","iopub.execute_input":"2023-11-30T07:14:07.384810Z","iopub.status.idle":"2023-11-30T07:14:07.401612Z","shell.execute_reply.started":"2023-11-30T07:14:07.384774Z","shell.execute_reply":"2023-11-30T07:14:07.400701Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"train=pd.concat([train,train1])","metadata":{"execution":{"iopub.status.busy":"2023-11-30T07:14:07.402672Z","iopub.execute_input":"2023-11-30T07:14:07.402962Z","iopub.status.idle":"2023-11-30T07:14:07.408934Z","shell.execute_reply.started":"2023-11-30T07:14:07.402931Z","shell.execute_reply":"2023-11-30T07:14:07.408125Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"train_ratio = 0.8\ntrain_size = int(len(training_data) * train_ratio)\n\ntrain_dataset = training_data[:train_size]\ndev_dataset = training_data[train_size:]","metadata":{"execution":{"iopub.status.busy":"2023-11-30T07:14:07.410156Z","iopub.execute_input":"2023-11-30T07:14:07.410437Z","iopub.status.idle":"2023-11-30T07:14:07.432183Z","shell.execute_reply.started":"2023-11-30T07:14:07.410391Z","shell.execute_reply":"2023-11-30T07:14:07.431448Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"text = train_dataset['text']\nlabels = train_dataset['label']","metadata":{"execution":{"iopub.status.busy":"2023-11-30T07:14:07.433078Z","iopub.execute_input":"2023-11-30T07:14:07.433320Z","iopub.status.idle":"2023-11-30T07:14:07.456312Z","shell.execute_reply.started":"2023-11-30T07:14:07.433292Z","shell.execute_reply":"2023-11-30T07:14:07.455666Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\n\ndef build_vocabulary(data, min_occurrences=5):\n    all_words = [word for essay in data['text'] for word in essay.split()]\n    word_counts = Counter(all_words)\n    \n    # Choose words that occur less than min_occurrences times\n    rare_words = [word for word, count in word_counts.items() if count < min_occurrences]\n    \n    # Exclude rare words from the vocabulary\n    vocabulary = list(set(all_words) - set(rare_words))\n    \n    reverse_index = {word: index for index, word in enumerate(vocabulary)}\n    \n    return vocabulary, reverse_index\n\nvocabulary, reverse_index = build_vocabulary(train)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T07:14:07.457176Z","iopub.execute_input":"2023-11-30T07:14:07.457427Z","iopub.status.idle":"2023-11-30T07:14:10.419410Z","shell.execute_reply.started":"2023-11-30T07:14:07.457388Z","shell.execute_reply":"2023-11-30T07:14:10.418566Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"def train_naive_bayes_classifier(documents, labels, alpha):\n    class_probs = defaultdict(float)\n    word_probs = defaultdict(lambda: defaultdict(float))\n    classes = set()\n\n    class_counts = defaultdict(int)\n    for label in labels:\n        class_counts[label] += 1\n        classes.add(label)\n\n    total_documents = len(labels)\n\n    for label, count in class_counts.items():\n        class_probs[label] = count / total_documents\n\n    word_counts = defaultdict(lambda: defaultdict(int))\n\n    for doc, label in zip(documents, labels):\n        words = re.findall(r'\\b\\w+\\b', doc.lower())\n        for word in words:\n            word_counts[label][word] += 1\n\n    for label in classes:\n        total_words_in_class = sum(word_counts[label].values())\n        total_unique_words = len(set(word_counts[label].keys()))\n\n        for word, count in word_counts[label].items():\n            word_probs[label][word] = (count + alpha) / (total_words_in_class + alpha * total_unique_words)\n\n    return class_probs, word_probs, classes\n\ndef predict_naive_bayes_classifier(documents, class_probs, word_probs, classes):\n    predictions = []\n\n    for document in documents:\n        words = re.findall(r'\\b\\w+\\b', str(document).lower())\n        scores = defaultdict(float)\n\n        for label in classes:\n            scores[label] = log(class_probs[label])\n\n            for word in words:\n                scores[label] += log(word_probs[label].get(word, 1e-10))\n\n        exp_scores = {label: exp(score) for label, score in scores.items()}\n        sum_exp_scores = sum(exp_scores.values())\n\n        if sum_exp_scores == 0:\n            probabilities = {label: 1 / len(classes) for label in classes}\n        else:\n            probabilities = {label: exp_score / sum_exp_scores for label, exp_score in exp_scores.items()}\n\n        predictions.append(probabilities)\n\n    return predictions\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T07:14:10.421609Z","iopub.execute_input":"2023-11-30T07:14:10.421944Z","iopub.status.idle":"2023-11-30T07:14:10.433614Z","shell.execute_reply.started":"2023-11-30T07:14:10.421902Z","shell.execute_reply":"2023-11-30T07:14:10.432875Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"dev_data_text = dev_dataset['text']\ndev_data_labels = dev_dataset['label']","metadata":{"execution":{"iopub.status.busy":"2023-11-30T07:14:10.434462Z","iopub.execute_input":"2023-11-30T07:14:10.434715Z","iopub.status.idle":"2023-11-30T07:14:10.449069Z","shell.execute_reply.started":"2023-11-30T07:14:10.434686Z","shell.execute_reply":"2023-11-30T07:14:10.448442Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"alpha_values_to_try = [0.01, 0.1, 0.5, 1.0, 5.0, 10.0]\nfor alpha in alpha_values_to_try:\n    class_probs, word_probs, classes = train_naive_bayes_classifier(text, labels, alpha)\n    predictions = predict_naive_bayes_classifier(dev_data_text, class_probs, word_probs, classes)\n    result=[]\n    for i in range(len(predictions)):\n        if(predictions[i][0] >= predictions[i][1]):\n            result.append(0)\n        else:\n            result.append(1)\n    count = 0\n    for i in range(len(result)):\n        if(result[i] == dev_data_labels.iloc[i]):\n            count = count + 1\n\n    accuracy = count / len(result)\n    print(\"For alpha value:\", alpha, \"Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T07:14:10.449866Z","iopub.execute_input":"2023-11-30T07:14:10.450110Z","iopub.status.idle":"2023-11-30T07:15:23.694484Z","shell.execute_reply.started":"2023-11-30T07:14:10.450082Z","shell.execute_reply":"2023-11-30T07:15:23.693319Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"For alpha value: 0.01 Accuracy: 0.1586806329396033\nFor alpha value: 0.1 Accuracy: 0.1586806329396033\nFor alpha value: 0.5 Accuracy: 0.1586806329396033\nFor alpha value: 1.0 Accuracy: 0.1586806329396033\nFor alpha value: 5.0 Accuracy: 0.15856919991085358\nFor alpha value: 10.0 Accuracy: 0.15856919991085358\n","output_type":"stream"}]},{"cell_type":"code","source":"from collections import Counter\n\ndef calculate_probabilities(data, vocabulary):\n    # Calculate occurrence probability\n    total_documents = len(data)\n    word_counts = Counter(' '.join([row['text'] for row in data]).split())\n    occurrence_probability = {word: word_counts[word] / total_documents for word in vocabulary}\n\n    # Calculate conditional probability\n    llm_documents = [row['text'] for row in data if row['generated'] == 1]\n    llm_word_counts = Counter(' '.join(llm_documents).split())\n    conditional_probability_llm = {word: llm_word_counts[word] / len(llm_documents) for word in vocabulary}\n\n    return occurrence_probability, conditional_probability_llm\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T07:15:33.743336Z","iopub.execute_input":"2023-11-30T07:15:33.744186Z","iopub.status.idle":"2023-11-30T07:15:33.749841Z","shell.execute_reply.started":"2023-11-30T07:15:33.744144Z","shell.execute_reply":"2023-11-30T07:15:33.748955Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"occurrence_probability, conditional_probability_llm = calculate_probabilities(training_dataset, vocabulary)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T07:15:35.611954Z","iopub.execute_input":"2023-11-30T07:15:35.612776Z","iopub.status.idle":"2023-11-30T07:15:35.817631Z","shell.execute_reply.started":"2023-11-30T07:15:35.612736Z","shell.execute_reply":"2023-11-30T07:15:35.816710Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# Derive Top 10 words that predict each class\ntop_10_llm_words = sorted(vocabulary, key=lambda word: conditional_probability_llm[word], reverse=True)[:10]\ntop_10_human_words = sorted(vocabulary, key=lambda word: occurrence_probability[word], reverse=True)[:10]\n\nprint(\"Top 10 words predicting LLM essays:\", top_10_llm_words)\nprint(\"Top 10 words predicting human essays:\", top_10_human_words)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T07:16:10.961799Z","iopub.execute_input":"2023-11-30T07:16:10.962178Z","iopub.status.idle":"2023-11-30T07:16:10.999693Z","shell.execute_reply.started":"2023-11-30T07:16:10.962144Z","shell.execute_reply":"2023-11-30T07:16:10.998826Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Top 10 words predicting LLM essays: ['the', 'of', 'to', 'for', 'a', 'and', 'that', 'votes', 'is', 'in']\nTop 10 words predicting human essays: ['the', 'to', 'of', 'a', 'and', 'in', 'is', 'that', 'for', 'are']\n","output_type":"stream"}]},{"cell_type":"code","source":"test_text = test_data['text']\nprint(test_text)\ntesting_data_probabilities = predict_naive_bayes_classifier(test_text, class_probs, word_probs, classes)\nprint(testing_data_probabilities)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T07:20:41.364185Z","iopub.execute_input":"2023-11-30T07:20:41.365216Z","iopub.status.idle":"2023-11-30T07:20:41.370526Z","shell.execute_reply.started":"2023-11-30T07:20:41.365174Z","shell.execute_reply":"2023-11-30T07:20:41.369735Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"0    Aaa bbb ccc.\n1    Bbb ccc ddd.\n2    CCC ddd eee.\nName: text, dtype: object\n[{0: 0.6704230005462533, 1: 0.3295769994537467}, {0: 0.7242436061737354, 1: 0.2757563938262646}, {0: 0.7242436061737354, 1: 0.2757563938262646}]\n","output_type":"stream"}]},{"cell_type":"code","source":"final_testing_output = []\nfor i in testing_data_probabilities:\n    final_testing_output.append(i[1])\npredicted_output = np.array(final_testing_output)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T07:23:26.598917Z","iopub.execute_input":"2023-11-30T07:23:26.599648Z","iopub.status.idle":"2023-11-30T07:23:26.604055Z","shell.execute_reply.started":"2023-11-30T07:23:26.599609Z","shell.execute_reply":"2023-11-30T07:23:26.603204Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"submission= pd.DataFrame({'id':test_data[\"id\"],'generated':predicted_output})\nsubmission.to_csv('submission.csv', index=False)\nprint(submission)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T07:24:40.511979Z","iopub.execute_input":"2023-11-30T07:24:40.512319Z","iopub.status.idle":"2023-11-30T07:24:40.521990Z","shell.execute_reply.started":"2023-11-30T07:24:40.512288Z","shell.execute_reply":"2023-11-30T07:24:40.521129Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"         id  generated\n0  0000aaaa   0.329577\n1  1111bbbb   0.275756\n2  2222cccc   0.275756\n","output_type":"stream"}]}]}